{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a37c21fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_movie_features_with_encoded_genres, split_train_test\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df146530",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample_long_sequences(df_lstm, max_length=2000):\n",
    "    \"\"\"\n",
    "    Downsample emotion sequences that exceed max_length.\n",
    "    \n",
    "    Args:\n",
    "        df_lstm: DataFrame with emotion_sequence_int column\n",
    "        max_length: Maximum desired sequence length\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with downsampled sequences\n",
    "    \"\"\"\n",
    "    df_downsampled = df_lstm.copy()\n",
    "    \n",
    "    def adaptive_downsample(seq):\n",
    "        if len(seq) > max_length:\n",
    "            # Calculate downsample factor\n",
    "            downsample_factor = len(seq) // max_length + 1\n",
    "            return seq[::downsample_factor]\n",
    "        else:\n",
    "            return seq\n",
    "    \n",
    "    # Apply downsampling\n",
    "    df_downsampled['emotion_sequence_int'] = df_downsampled['emotion_sequence_int'].apply(adaptive_downsample)\n",
    "    \n",
    "    # Update sequence lengths\n",
    "    df_downsampled['sequence_length'] = df_downsampled['emotion_sequence_int'].apply(len)\n",
    "        \n",
    "    return df_downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0324715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1643 movies\n",
      "Parsed emotion sequences to lists\n",
      "One-hot encoded 23 genres\n",
      "Converted emotion sequences to integer encoding for LSTM\n",
      "Split dataset:\n",
      "  Training: 1314 movies (80%)\n",
      "  Testing:  329 movies (20%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-29 19:05:30.492772: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-29 19:05:30.707179: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-11-29 19:05:30.707308: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-11-29 19:05:30.748576: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-11-29 19:05:30.820416: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-29 19:05:31.845158: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/shane/miniconda3/envs/nlp/lib/python3.11/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from utils import load_movie_features_with_encoded_genres, prepare_for_lstm, split_train_test, genres\n",
    "\n",
    "# Load data\n",
    "df_original, df_with_genres = load_movie_features_with_encoded_genres('movie_features.csv')\n",
    "\n",
    "# Prepare for LSTM\n",
    "df_lstm = prepare_for_lstm(df_with_genres)\n",
    "\n",
    "df_lstm = downsample_long_sequences(df_lstm, max_length=2000)\n",
    "\n",
    "# Split\n",
    "df_train, df_test = split_train_test(df_lstm, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to X, y\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "X_train_seqs = df_train['emotion_sequence_int'].tolist()\n",
    "X_test_seqs = df_test['emotion_sequence_int'].tolist()\n",
    "\n",
    "max_length = max(max(len(seq) for seq in X_train_seqs), max(len(seq) for seq in X_test_seqs))\n",
    "\n",
    "X_train = pad_sequences(X_train_seqs, maxlen=max_length, padding='post')\n",
    "X_test = pad_sequences(X_test_seqs, maxlen=max_length, padding='post')\n",
    "\n",
    "y_train = df_train[genres].values\n",
    "y_test = df_test[genres].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "676f21d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genre frequencies:\n",
      "Drama            988 (60.1%)\n",
      "Thriller         550 (33.5%)\n",
      "Comedy           519 (31.6%)\n",
      "Action           405 (24.7%)\n",
      "Crime            337 (20.5%)\n",
      "Romance          327 (19.9%)\n",
      "Adventure        284 (17.3%)\n",
      "Sci-Fi           234 (14.2%)\n",
      "Horror           218 (13.3%)\n",
      "Mystery          213 (13.0%)\n",
      "Fantasy          190 (11.6%)\n",
      "Biography        162 (9.9%)\n",
      "Family            86 (5.2%)\n",
      "History           81 (4.9%)\n",
      "War               68 (4.1%)\n",
      "Music             58 (3.5%)\n",
      "Animation         49 (3.0%)\n",
      "Sport             45 (2.7%)\n",
      "Musical           32 (1.9%)\n",
      "Western           22 (1.3%)\n",
      "Short             11 (0.7%)\n",
      "Film-Noir         10 (0.6%)\n",
      "Documentary        3 (0.2%)\n",
      "\n",
      "Total movies: 1643\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Count genre occurrences\n",
    "genre_counts = Counter()\n",
    "\n",
    "for genres_str in df_lstm['genres'].dropna():\n",
    "    genre_list = [g.strip() for g in str(genres_str).split(',')]\n",
    "    genre_counts.update(genre_list)\n",
    "\n",
    "# Sort by frequency\n",
    "sorted_genres = sorted(genre_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"Genre frequencies:\")\n",
    "for genre, count in sorted_genres:\n",
    "    percentage = (count / len(df_lstm)) * 100\n",
    "    print(f\"{genre:15} {count:4} ({percentage:.1f}%)\")\n",
    "\n",
    "print(f\"\\nTotal movies: {len(df_lstm)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d78d533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sequence length: 6808\n",
      "Training data shape: (1314, 6808)\n",
      "Memory estimate: 0.03 GB\n"
     ]
    }
   ],
   "source": [
    "print(f\"Max sequence length: {max_length}\")\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Memory estimate: {X_train.nbytes / (1024**3):.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c58a016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF OK: 2.15.0\n",
      "GPU: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-29 19:05:33.234424: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:c4:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-11-29 19:05:33.608784: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "# Sanity check\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"TF OK:\", tf.__version__)\n",
    "print(\"GPU:\", tf.config.list_physical_devices(\"GPU\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81de5a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (1314, 6808)\n",
      "Training labels shape: (1314, 23)\n",
      "\n",
      "Model Summary:\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 6808, 32)          224       \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 64)                24832     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                4160      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 23)                1495      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 30711 (119.96 KB)\n",
      "Trainable params: 30711 (119.96 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "\n",
      "Training with 20% validation split...\n",
      "Epoch 1/10\n",
      "33/33 [==============================] - 93s 3s/step - loss: 0.5872 - precision: 0.2175 - recall: 0.4005 - auc: 0.4736 - val_loss: 0.3688 - val_precision: 0.5856 - val_recall: 0.1904 - val_auc: 0.5000\n",
      "Epoch 2/10\n",
      "33/33 [==============================] - 90s 3s/step - loss: 0.3954 - precision: 0.3500 - recall: 0.2433 - auc: 0.4787 - val_loss: 0.3280 - val_precision: 0.5856 - val_recall: 0.1904 - val_auc: 0.5000\n",
      "Epoch 3/10\n",
      "33/33 [==============================] - 88s 3s/step - loss: 0.3586 - precision: 0.4421 - recall: 0.1909 - auc: 0.4834 - val_loss: 0.3246 - val_precision: 0.5856 - val_recall: 0.1904 - val_auc: 0.5000\n",
      "Epoch 4/10\n",
      "33/33 [==============================] - 89s 3s/step - loss: 0.3441 - precision: 0.4864 - recall: 0.1890 - auc: 0.4883 - val_loss: 0.3227 - val_precision: 0.5856 - val_recall: 0.1904 - val_auc: 0.5000\n",
      "Epoch 5/10\n",
      "33/33 [==============================] - 89s 3s/step - loss: 0.3401 - precision: 0.5248 - recall: 0.1797 - auc: 0.5057 - val_loss: 0.3216 - val_precision: 0.5856 - val_recall: 0.1904 - val_auc: 0.5000\n",
      "Epoch 6/10\n",
      "33/33 [==============================] - 90s 3s/step - loss: 0.3361 - precision: 0.5277 - recall: 0.1836 - auc: 0.4951 - val_loss: 0.3210 - val_precision: 0.5856 - val_recall: 0.1904 - val_auc: 0.5000\n",
      "Epoch 7/10\n",
      "33/33 [==============================] - 94s 3s/step - loss: 0.3329 - precision: 0.5566 - recall: 0.1672 - auc: 0.4875 - val_loss: 0.3206 - val_precision: 0.5856 - val_recall: 0.1904 - val_auc: 0.5000\n",
      "Epoch 8/10\n",
      "33/33 [==============================] - 95s 3s/step - loss: 0.3281 - precision: 0.5509 - recall: 0.1823 - auc: 0.5244 - val_loss: 0.3204 - val_precision: 0.5856 - val_recall: 0.1904 - val_auc: 0.5000\n",
      "Epoch 9/10\n",
      "33/33 [==============================] - 95s 3s/step - loss: 0.3264 - precision: 0.5613 - recall: 0.1720 - auc: 0.4723 - val_loss: 0.3202 - val_precision: 0.5856 - val_recall: 0.1904 - val_auc: 0.5000\n",
      "Epoch 10/10\n",
      "33/33 [==============================] - 92s 3s/step - loss: 0.3276 - precision: 0.5629 - recall: 0.1794 - auc: 0.4586 - val_loss: 0.3199 - val_precision: 0.5856 - val_recall: 0.1904 - val_auc: 0.5000\n",
      "\n",
      "Model trained on full training set\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 51\u001b[39m\n\u001b[32m     42\u001b[39m history = model.fit(\n\u001b[32m     43\u001b[39m     X_train, y_train,\n\u001b[32m     44\u001b[39m     epochs=\u001b[32m10\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     47\u001b[39m     verbose=\u001b[32m1\u001b[39m\n\u001b[32m     48\u001b[39m )\n\u001b[32m     50\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mModel trained on full training set\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFinal Training Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mhistory\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43maccuracy\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m[-\u001b[32m1\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     52\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFinal Validation Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhistory.history[\u001b[33m'\u001b[39m\u001b[33mval_accuracy\u001b[39m\u001b[33m'\u001b[39m][-\u001b[32m1\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: 'accuracy'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from utils import genres, emotions\n",
    "import numpy as np\n",
    "from tensorflow.keras.metrics import Precision, Recall, AUC\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'  # Force CPU\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Prepare data (X_train, y_train already created from previous steps)\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Training labels shape: {y_train.shape}\")\n",
    "\n",
    "# Build LSTM model\n",
    "model = models.Sequential([\n",
    "    layers.Embedding(input_dim=len(emotions), output_dim=32, input_length=max_length),\n",
    "    layers.LSTM(64, return_sequences=False),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(len(genres), activation='sigmoid')\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[\n",
    "        Precision(name='precision'),\n",
    "        Recall(name='recall'),\n",
    "        AUC(name='auc', multi_label=True)\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"\\nModel Summary:\")\n",
    "model.summary()\n",
    "\n",
    "# Train with validation split (similar to cross-validation)\n",
    "print(\"\\nTraining with 20% validation split...\")\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nModel trained on full training set\")\n",
    "print(f\"Final Training Precision: {history.history['precision'][-1]:.4f}\")\n",
    "print(f\"Final Training Recall: {history.history['recall'][-1]:.4f}\")\n",
    "print(f\"Final Validation Precision: {history.history['val_precision'][-1]:.4f}\")\n",
    "print(f\"Final Validation Recall: {history.history['val_recall'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "041f84c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 5s 469ms/step\n",
      "Per-Label Accuracy: 0.8778\n",
      "Jaccard Score (avg overlap): 0.2467\n",
      "F1 Score: 0.3328\n",
      "Exact Match: 0.0608\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import hamming_loss, jaccard_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Predict (X_test, y_test already created from previous steps)\n",
    "y_pred_proba = model.predict(X_test)\n",
    "y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "\n",
    "# Per-label accuracy\n",
    "per_label_accuracy = 1 - hamming_loss(y_test, y_pred)\n",
    "print(f\"Per-Label Accuracy: {per_label_accuracy:.4f}\")\n",
    "\n",
    "# Jaccard score\n",
    "jaccard = jaccard_score(y_test, y_pred, average='samples')\n",
    "print(f\"Jaccard Score (avg overlap): {jaccard:.4f}\")\n",
    "\n",
    "# F1 score\n",
    "f1 = f1_score(y_test, y_pred, average='samples', zero_division=0)\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Exact match\n",
    "exact_match = np.mean([np.array_equal(y_test[i], y_pred[i]) for i in range(len(y_test))])\n",
    "print(f\"Exact Match: {exact_match:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e3cfd48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "LSTM DIAGNOSTIC REPORT\n",
      "================================================================================\n",
      "\n",
      "1. INPUT SEQUENCES (first 20 emotions):\n",
      "   Test movie 0: [6 6 1 2 0 2 6 6 6 6 6 0 6 6 6 2 2 2 5 1]\n",
      "   Test movie 1: [2 5 6 2 2 2 6 6 5 4 0 0 0 2 6 6 6 6 4 6]\n",
      "   Test movie 2: [3 6 3 6 6 3 5 1 1 6 6 3 0 6 3 6 3 2 5 4]\n",
      "   Sequences identical? False\n",
      "\n",
      "2. EMBEDDING LAYER:\n",
      "   Output 0 sample: [-0.04548707 -0.00129836 -0.0230341   0.00783323  0.02307265]\n",
      "   Output 1 sample: [-0.02388824  0.028193    0.04022922 -0.02470715 -0.02971494]\n",
      "   Embeddings identical? False\n",
      "WARNING:tensorflow:5 out of the last 40 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa2bc0a3600> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "3. LSTM LAYER:\n",
      "   Output 0: [-0.04494485 -0.4543881  -0.49469566 -0.43969    -0.4204751   0.18315892\n",
      "  0.37721047 -0.40435907 -0.10088176  0.3099661 ]\n",
      "   Output 1: [-0.04494485 -0.45438802 -0.49469572 -0.43969    -0.42047504  0.18315892\n",
      "  0.37721053 -0.40435907 -0.10088176  0.30996606]\n",
      "   LSTM outputs identical? True\n",
      "\n",
      "4. FINAL PREDICTIONS (probabilities):\n",
      "   Movie 0: [0.23888312 0.17057236 0.0254903  0.09667966 0.30561358 0.20302154\n",
      " 0.01370833 0.60313576 0.05355994 0.10688362]\n",
      "   Movie 1: [0.23888312 0.17057236 0.0254903  0.09667964 0.30561358 0.20302151\n",
      " 0.01370832 0.60313576 0.05355994 0.10688362]\n",
      "   Movie 2: [0.23888312 0.17057236 0.0254903  0.09667964 0.30561358 0.20302154\n",
      " 0.01370833 0.60313576 0.05355994 0.10688362]\n",
      "   All predictions identical? True\n",
      "\n",
      "5. BINARY PREDICTIONS:\n",
      "   Movie 0 genres: ['Drama']\n",
      "   Movie 1 genres: ['Drama']\n",
      "   Always predicting same genre? True\n",
      "\n",
      "6. OVERALL TEST SET:\n",
      "   Average predicted genres per movie: 1.00\n",
      "   Average true genres per movie: 3.02\n",
      "   Most common prediction: Drama\n",
      "\n",
      "================================================================================\n",
      "CONCLUSION:\n",
      "  Inputs: DIFFERENT\n",
      "  Embeddings: DIFFERENT\n",
      "  LSTM outputs: IDENTICAL <<< BROKEN HERE\n",
      "  Final predictions: IDENTICAL\n",
      "\n",
      "  The LSTM layer is not processing inputs - outputting constant vector.\n",
      "  Likely cause: Vanishing gradients with 6808 timestep sequences.\n",
      "  Fix: Downsample sequences to 1500-2000 and retrain.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from utils import genres\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"LSTM DIAGNOSTIC REPORT\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 1. Check input sequences are different\n",
    "print(\"\\n1. INPUT SEQUENCES (first 20 emotions):\")\n",
    "print(f\"   Test movie 0: {X_test[0][:20]}\")\n",
    "print(f\"   Test movie 1: {X_test[1][:20]}\")\n",
    "print(f\"   Test movie 2: {X_test[2][:20]}\")\n",
    "print(f\"   Sequences identical? {np.array_equal(X_test[0], X_test[1])}\")\n",
    "\n",
    "# 2. Check embeddings are different\n",
    "from tensorflow.keras import Model\n",
    "embedding_model = Model(inputs=model.input, outputs=model.layers[0].output)\n",
    "embed_0 = embedding_model.predict(X_test[0:1], verbose=0)\n",
    "embed_1 = embedding_model.predict(X_test[1:2], verbose=0)\n",
    "print(f\"\\n2. EMBEDDING LAYER:\")\n",
    "print(f\"   Output 0 sample: {embed_0[0][0][:5]}\")\n",
    "print(f\"   Output 1 sample: {embed_1[0][0][:5]}\")\n",
    "print(f\"   Embeddings identical? {np.allclose(embed_0, embed_1)}\")\n",
    "\n",
    "# 3. Check LSTM outputs\n",
    "lstm_model = Model(inputs=model.input, outputs=model.layers[1].output)\n",
    "lstm_0 = lstm_model.predict(X_test[0:1], verbose=0)\n",
    "lstm_1 = lstm_model.predict(X_test[1:2], verbose=0)\n",
    "print(f\"\\n3. LSTM LAYER:\")\n",
    "print(f\"   Output 0: {lstm_0[0][:10]}\")\n",
    "print(f\"   Output 1: {lstm_1[0][:10]}\")\n",
    "print(f\"   LSTM outputs identical? {np.allclose(lstm_0, lstm_1)}\")\n",
    "\n",
    "# 4. Check final predictions\n",
    "pred_0 = model.predict(X_test[0:1], verbose=0)[0]\n",
    "pred_1 = model.predict(X_test[1:2], verbose=0)[0]\n",
    "pred_2 = model.predict(X_test[2:3], verbose=0)[0]\n",
    "print(f\"\\n4. FINAL PREDICTIONS (probabilities):\")\n",
    "print(f\"   Movie 0: {pred_0[:10]}\")\n",
    "print(f\"   Movie 1: {pred_1[:10]}\")\n",
    "print(f\"   Movie 2: {pred_2[:10]}\")\n",
    "print(f\"   All predictions identical? {np.allclose(pred_0, pred_1) and np.allclose(pred_1, pred_2)}\")\n",
    "\n",
    "# 5. Check prediction behavior\n",
    "pred_0_binary = (pred_0 > 0.5).astype(int)\n",
    "pred_1_binary = (pred_1 > 0.5).astype(int)\n",
    "print(f\"\\n5. BINARY PREDICTIONS:\")\n",
    "print(f\"   Movie 0 genres: {[genres[i] for i in range(len(genres)) if pred_0_binary[i] == 1]}\")\n",
    "print(f\"   Movie 1 genres: {[genres[i] for i in range(len(genres)) if pred_1_binary[i] == 1]}\")\n",
    "print(f\"   Always predicting same genre? {np.array_equal(pred_0_binary, pred_1_binary)}\")\n",
    "\n",
    "# 6. Overall test predictions\n",
    "y_pred_all = model.predict(X_test, verbose=0)\n",
    "y_pred_binary_all = (y_pred_all > 0.5).astype(int)\n",
    "print(f\"\\n6. OVERALL TEST SET:\")\n",
    "print(f\"   Average predicted genres per movie: {y_pred_binary_all.sum(axis=1).mean():.2f}\")\n",
    "print(f\"   Average true genres per movie: {y_test.sum(axis=1).mean():.2f}\")\n",
    "print(f\"   Most common prediction: {genres[np.argmax(y_pred_all.mean(axis=0))]}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CONCLUSION:\")\n",
    "print(\"  Inputs: DIFFERENT\")\n",
    "print(\"  Embeddings: DIFFERENT\")\n",
    "print(\"  LSTM outputs: IDENTICAL <<< BROKEN HERE\")\n",
    "print(\"  Final predictions: IDENTICAL\")\n",
    "print(\"\\n  The LSTM layer is not processing inputs - outputting constant vector.\")\n",
    "print(\"  Likely cause: Vanishing gradients with 6808 timestep sequences.\")\n",
    "print(\"  Fix: Downsample sequences to 1500-2000 and retrain.\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3654166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model \n",
    "\n",
    "#model.save('lstm_model.keras')\n",
    "#print(\"Model saved to lstm_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6f67a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model \n",
    "\"\"\" from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the saved model\n",
    "model = load_model('lstm_model.keras')\n",
    "print(\"Model loaded successfully\")\n",
    "\n",
    "# Now you can use it for predictions\n",
    "y_pred = model.predict(X_test) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb96e5ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 83ms/step\n",
      "True [0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0]\n",
      "Pred [0.23888311 0.17057236 0.0254903  0.09667966 0.30561358 0.20302154\n",
      " 0.01370833 0.60313576 0.05355995 0.1068836  0.01418324 0.04999492\n",
      " 0.12211634 0.04637704 0.01881817 0.13074085 0.19230515 0.13748014\n",
      " 0.01391637 0.03432674 0.33136564 0.05314127 0.017088  ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from utils import genres\n",
    "\n",
    "# Pick random sample\n",
    "random_idx = np.random.randint(0, len(X_test))\n",
    "\n",
    "# Get data\n",
    "random_test = X_test[random_idx:random_idx+1]\n",
    "y_true = y_test[random_idx]\n",
    "\n",
    "\n",
    "\n",
    "y_pred = model.predict(random_test)[0]\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "print(f\"True {y_true}\")\n",
    "print(f\"Pred {y_pred_binary}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
