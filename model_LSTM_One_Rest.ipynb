{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42f882ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./venv/lib/python3.12/site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in ./venv/lib/python3.12/site-packages (from pandas) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37c21fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "555786f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_train_test(df, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Split dataset into train and test sets.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame to split\n",
    "        test_size: Proportion of data for test set (0.0 to 1.0)\n",
    "        random_state: Random seed for reproducibility\n",
    "        \n",
    "    Returns:\n",
    "        df_train: Training set DataFrame\n",
    "        df_test: Test set DataFrame\n",
    "    \"\"\"\n",
    "    df_train, df_test = train_test_split(\n",
    "        df, \n",
    "        test_size=test_size, \n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    print(f\"Split dataset:\")\n",
    "    print(f\"  Training: {len(df_train)} movies ({(1-test_size)*100:.0f}%)\")\n",
    "    print(f\"  Testing:  {len(df_test)} movies ({test_size*100:.0f}%)\")\n",
    "    \n",
    "    return df_train, df_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e21bf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_movie_features_with_encoded_genres(filename):\n",
    "    \"\"\"\n",
    "    Load movie features CSV and one-hot encode genres.\n",
    "    \n",
    "    Args:\n",
    "        filename: Path to movie_features.csv\n",
    "        \n",
    "    Returns:\n",
    "        df_original: DataFrame with original string genres\n",
    "        df_with_genres: DataFrame with one-hot encoded genre columns and parsed emotion sequences\n",
    "    \"\"\"\n",
    "    df_original = pd.read_csv(filename)\n",
    "    print(f\"Loaded {len(df_original)} movies\")\n",
    "    \n",
    "    # Parse emotion_sequence from string to actual list\n",
    "    if 'emotion_sequence' in df_original.columns:\n",
    "        df_original['emotion_sequence'] = df_original['emotion_sequence'].apply(eval)\n",
    "        print(\"Parsed emotion sequences to lists\")\n",
    "    \n",
    "    # Create binary columns for each genre\n",
    "    df_with_genres = df_original.copy()\n",
    "    for genre in genres:\n",
    "        df_with_genres[genre] = df_with_genres['genres'].apply(\n",
    "            lambda x: 1 if pd.notna(x) and genre in str(x) else 0\n",
    "        )\n",
    "    \n",
    "    print(f\"One-hot encoded {len(genres)} genres\")\n",
    "    \n",
    "    return df_original, df_with_genres\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df146530",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample_long_sequences(df_lstm, max_length=2000):\n",
    "    \"\"\"\n",
    "    Downsample emotion sequences that exceed max_length.\n",
    "    \n",
    "    Args:\n",
    "        df_lstm: DataFrame with emotion_sequence_int column\n",
    "        max_length: Maximum desired sequence length\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with downsampled sequences\n",
    "    \"\"\"\n",
    "    df_downsampled = df_lstm.copy()\n",
    "    \n",
    "    def adaptive_downsample(seq):\n",
    "        if len(seq) > max_length:\n",
    "            # Calculate downsample factor\n",
    "            downsample_factor = len(seq) // max_length + 1\n",
    "            return seq[::downsample_factor]\n",
    "        else:\n",
    "            return seq\n",
    "    \n",
    "    # Apply downsampling\n",
    "    df_downsampled['emotion_sequence_int'] = df_downsampled['emotion_sequence_int'].apply(adaptive_downsample)\n",
    "    \n",
    "    # Update sequence lengths\n",
    "    df_downsampled['sequence_length'] = df_downsampled['emotion_sequence_int'].apply(len)\n",
    "        \n",
    "    return df_downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e962995",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_for_lstm(df_with_genres):\n",
    "    \"\"\"\n",
    "    Prepare data for LSTM by converting emotion sequences to integer sequences.\n",
    "    \n",
    "    Args:\n",
    "        df_with_genres: DataFrame with emotion_sequence column\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with emotion_sequence_int column (integer encoded sequences)\n",
    "    \"\"\"\n",
    "    df_lstm = df_with_genres.copy()\n",
    "    \n",
    "    # Encode emotions as integers\n",
    "    emotion_to_int = {emotion: i for i, emotion in enumerate(emotions)}\n",
    "    \n",
    "    # Convert emotion sequences to integer sequences\n",
    "    df_lstm['emotion_sequence_int'] = df_lstm['emotion_sequence'].apply(\n",
    "        lambda seq: [emotion_to_int[e] for e in seq]\n",
    "    )\n",
    "    \n",
    "    print(\"Converted emotion sequences to integer encoding for LSTM\")\n",
    "    \n",
    "    return df_lstm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0324715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1643 movies\n",
      "Parsed emotion sequences to lists\n",
      "One-hot encoded 23 genres\n",
      "Converted emotion sequences to integer encoding for LSTM\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m      9\u001b[39m df_lstm = prepare_for_lstm(df_with_genres)\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m#df_lstm = downsample_long_sequences(df_lstm, max_length=2000)\u001b[39;00m\n\u001b[32m     12\u001b[39m \n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Split\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m df_train, df_test = \u001b[43msplit_train_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_lstm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Convert to X, y\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msequence\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pad_sequences\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36msplit_train_test\u001b[39m\u001b[34m(df, test_size, random_state)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msplit_train_test\u001b[39m(df, test_size=\u001b[32m0.2\u001b[39m, random_state=\u001b[32m42\u001b[39m):\n\u001b[32m      2\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03m    Split dataset into train and test sets.\u001b[39;00m\n\u001b[32m      4\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m \u001b[33;03m        df_test: Test set DataFrame\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     df_train, df_test = \u001b[43mtrain_test_split\u001b[49m(\n\u001b[32m     15\u001b[39m         df, \n\u001b[32m     16\u001b[39m         test_size=test_size, \n\u001b[32m     17\u001b[39m         random_state=random_state\n\u001b[32m     18\u001b[39m     )\n\u001b[32m     20\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSplit dataset:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     21\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  Training: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df_train)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m movies (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(\u001b[32m1\u001b[39m-test_size)*\u001b[32m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.0f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m%)\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "genres =  ['Action', 'Adventure', 'Animation', 'Biography', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Family', 'Fantasy', 'Film-Noir', 'History', 'Horror', 'Music', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Short', 'Sport', 'Thriller', 'War', 'Western']\n",
    "emotions = ['anger', 'disgust', 'fear', 'joy', 'sadness', 'surprise', 'neutral']\n",
    "\n",
    "\n",
    "# Load data\n",
    "df_original, df_with_genres = load_movie_features_with_encoded_genres('movie_features.csv')\n",
    "\n",
    "# Prepare for LSTM\n",
    "df_lstm = prepare_for_lstm(df_with_genres)\n",
    "\n",
    "#df_lstm = downsample_long_sequences(df_lstm, max_length=2000)\n",
    "\n",
    "# Split\n",
    "df_train, df_test = split_train_test(df_lstm, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to X, y\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "X_train_seqs = df_train['emotion_sequence_int'].tolist()\n",
    "X_test_seqs = df_test['emotion_sequence_int'].tolist()\n",
    "\n",
    "max_length = max(max(len(seq) for seq in X_train_seqs), max(len(seq) for seq in X_test_seqs))\n",
    "\n",
    "X_train = pad_sequences(X_train_seqs, maxlen=max_length, padding='post')\n",
    "X_test = pad_sequences(X_test_seqs, maxlen=max_length, padding='post')\n",
    "\n",
    "y_train = df_train[genres].values\n",
    "y_test = df_test[genres].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676f21d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Count genre occurrences\n",
    "genre_counts = Counter()\n",
    "\n",
    "for genres_str in df_lstm['genres'].dropna():\n",
    "    genre_list = [g.strip() for g in str(genres_str).split(',')]\n",
    "    genre_counts.update(genre_list)\n",
    "\n",
    "# Sort by frequency\n",
    "sorted_genres = sorted(genre_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"Genre frequencies:\")\n",
    "for genre, count in sorted_genres:\n",
    "    percentage = (count / len(df_lstm)) * 100\n",
    "    print(f\"{genre:15} {count:4} ({percentage:.1f}%)\")\n",
    "\n",
    "print(f\"\\nTotal movies: {len(df_lstm)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d78d533",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Max sequence length: {max_length}\")\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Memory estimate: {X_train.nbytes / (1024**3):.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c58a016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"TF OK:\", tf.__version__)\n",
    "print(\"GPU:\", tf.config.list_physical_devices(\"GPU\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82e3ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"GPU devices:\", tf.config.list_physical_devices('GPU'))\n",
    "print(\"CUDA available:\", tf.test.is_built_with_cuda())\n",
    "\n",
    "# Check if GPU is actually being used\n",
    "import torch\n",
    "print(\"\\nPyTorch CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"PyTorch GPU:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81de5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from utils import genres, emotions\n",
    "import numpy as np\n",
    "from tensorflow.keras.metrics import Precision, Recall, AUC\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'  # Force CPU\n",
    "\n",
    "# Load and prepare data\n",
    "from utils import load_movie_features_with_encoded_genres, prepare_for_lstm, split_train_test\n",
    "\n",
    "df_original, df_with_genres = load_movie_features_with_encoded_genres('movie_features.csv')\n",
    "df_lstm = prepare_for_lstm(df_with_genres)\n",
    "\n",
    "# Split (no downsampling)\n",
    "df_train, df_test = split_train_test(df_lstm, test_size=0.2, random_state=42)\n",
    "\n",
    "# Get sequences\n",
    "X_train_seqs = df_train['emotion_sequence_int'].tolist()\n",
    "X_test_seqs = df_test['emotion_sequence_int'].tolist()\n",
    "\n",
    "# Pad to full max length\n",
    "max_length = max(max(len(seq) for seq in X_train_seqs), max(len(seq) for seq in X_test_seqs))\n",
    "print(f\"Max sequence length: {max_length}\")\n",
    "\n",
    "X_train = pad_sequences(X_train_seqs, maxlen=max_length, padding='post')\n",
    "X_test = pad_sequences(X_test_seqs, maxlen=max_length, padding='post')\n",
    "\n",
    "y_train = df_train[genres].values\n",
    "y_test = df_test[genres].values\n",
    "\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Training labels shape: {y_train.shape}\")\n",
    "\n",
    "# Create binary LSTM model\n",
    "def create_binary_lstm(max_length):\n",
    "    model = models.Sequential([\n",
    "        layers.Embedding(input_dim=len(emotions), output_dim=32, input_length=max_length),\n",
    "        layers.LSTM(64, return_sequences=False),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(1, activation='sigmoid')  # Binary output\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=[\n",
    "            Precision(name='precision'),\n",
    "            Recall(name='recall'),\n",
    "            AUC(name='auc')\n",
    "        ]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Train one model per genre\n",
    "trained_models = {}\n",
    "histories = {}\n",
    "\n",
    "for i, genre in enumerate(genres):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Training model {i+1}/{len(genres)}: {genre}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Check class balance\n",
    "    pos_count = y_train[:, i].sum()\n",
    "    neg_count = len(y_train) - pos_count\n",
    "    print(f\"Positive samples: {pos_count} ({pos_count/len(y_train)*100:.1f}%)\")\n",
    "    print(f\"Negative samples: {neg_count} ({neg_count/len(y_train)*100:.1f}%)\")\n",
    "    \n",
    "    # Create and train model\n",
    "    model = create_binary_lstm(max_length)\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train,\n",
    "        y_train[:, i],  # Single binary column\n",
    "        epochs=20,\n",
    "        batch_size=32,\n",
    "        validation_split=0.2,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Store model and history\n",
    "    trained_models[genre] = model\n",
    "    histories[genre] = history\n",
    "    \n",
    "    # Save model\n",
    "    model.save(f'lstm_binary_{genre.replace(\"-\", \"_\")}.keras')\n",
    "    print(f\"Saved model for {genre}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"All models trained\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Make predictions\n",
    "print(\"\\nGenerating predictions on test set...\")\n",
    "predictions_dict = {}\n",
    "\n",
    "for genre in genres:\n",
    "    print(f\"Predicting {genre}...\")\n",
    "    model = trained_models[genre]\n",
    "    pred_proba = model.predict(X_test, verbose=0).flatten()\n",
    "    predictions_dict[genre] = pred_proba\n",
    "\n",
    "# Convert to array format\n",
    "y_pred_proba = np.column_stack([predictions_dict[g] for g in genres])\n",
    "y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "\n",
    "# Evaluate\n",
    "from sklearn.metrics import hamming_loss, jaccard_score, f1_score\n",
    "\n",
    "per_label_accuracy = 1 - hamming_loss(y_test, y_pred)\n",
    "jaccard = jaccard_score(y_test, y_pred, average='samples')\n",
    "f1 = f1_score(y_test, y_pred, average='samples', zero_division=0)\n",
    "exact_match = np.mean([np.array_equal(y_test[i], y_pred[i]) for i in range(len(y_test))])\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL RESULTS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Per-Label Accuracy: {per_label_accuracy:.4f}\")\n",
    "print(f\"Jaccard Score: {jaccard:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Exact Match: {exact_match:.4f}\")\n",
    "print(f\"\\nAverage predicted genres per movie: {y_pred.sum(axis=1).mean():.2f}\")\n",
    "print(f\"Average true genres per movie: {y_test.sum(axis=1).mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041f84c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import hamming_loss, jaccard_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Predict (X_test, y_test already created from previous steps)\n",
    "y_pred_proba = model.predict(X_test)\n",
    "y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "\n",
    "# Per-label accuracy\n",
    "per_label_accuracy = 1 - hamming_loss(y_test, y_pred)\n",
    "print(f\"Per-Label Accuracy: {per_label_accuracy:.4f}\")\n",
    "\n",
    "# Jaccard score\n",
    "jaccard = jaccard_score(y_test, y_pred, average='samples')\n",
    "print(f\"Jaccard Score (avg overlap): {jaccard:.4f}\")\n",
    "\n",
    "# F1 score\n",
    "f1 = f1_score(y_test, y_pred, average='samples', zero_division=0)\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Exact match\n",
    "exact_match = np.mean([np.array_equal(y_test[i], y_pred[i]) for i in range(len(y_test))])\n",
    "print(f\"Exact Match: {exact_match:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cfd48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils import genres\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"LSTM DIAGNOSTIC REPORT\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 1. Check input sequences are different\n",
    "print(\"\\n1. INPUT SEQUENCES (first 20 emotions):\")\n",
    "print(f\"   Test movie 0: {X_test[0][:20]}\")\n",
    "print(f\"   Test movie 1: {X_test[1][:20]}\")\n",
    "print(f\"   Test movie 2: {X_test[2][:20]}\")\n",
    "print(f\"   Sequences identical? {np.array_equal(X_test[0], X_test[1])}\")\n",
    "\n",
    "# 2. Check embeddings are different\n",
    "from tensorflow.keras import Model\n",
    "embedding_model = Model(inputs=model.input, outputs=model.layers[0].output)\n",
    "embed_0 = embedding_model.predict(X_test[0:1], verbose=0)\n",
    "embed_1 = embedding_model.predict(X_test[1:2], verbose=0)\n",
    "print(f\"\\n2. EMBEDDING LAYER:\")\n",
    "print(f\"   Output 0 sample: {embed_0[0][0][:5]}\")\n",
    "print(f\"   Output 1 sample: {embed_1[0][0][:5]}\")\n",
    "print(f\"   Embeddings identical? {np.allclose(embed_0, embed_1)}\")\n",
    "\n",
    "# 3. Check LSTM outputs\n",
    "lstm_model = Model(inputs=model.input, outputs=model.layers[1].output)\n",
    "lstm_0 = lstm_model.predict(X_test[0:1], verbose=0)\n",
    "lstm_1 = lstm_model.predict(X_test[1:2], verbose=0)\n",
    "print(f\"\\n3. LSTM LAYER:\")\n",
    "print(f\"   Output 0: {lstm_0[0][:10]}\")\n",
    "print(f\"   Output 1: {lstm_1[0][:10]}\")\n",
    "print(f\"   LSTM outputs identical? {np.allclose(lstm_0, lstm_1)}\")\n",
    "\n",
    "# 4. Check final predictions\n",
    "pred_0 = model.predict(X_test[0:1], verbose=0)[0]\n",
    "pred_1 = model.predict(X_test[1:2], verbose=0)[0]\n",
    "pred_2 = model.predict(X_test[2:3], verbose=0)[0]\n",
    "print(f\"\\n4. FINAL PREDICTIONS (probabilities):\")\n",
    "print(f\"   Movie 0: {pred_0[:10]}\")\n",
    "print(f\"   Movie 1: {pred_1[:10]}\")\n",
    "print(f\"   Movie 2: {pred_2[:10]}\")\n",
    "print(f\"   All predictions identical? {np.allclose(pred_0, pred_1) and np.allclose(pred_1, pred_2)}\")\n",
    "\n",
    "# 5. Check prediction behavior\n",
    "pred_0_binary = (pred_0 > 0.5).astype(int)\n",
    "pred_1_binary = (pred_1 > 0.5).astype(int)\n",
    "print(f\"\\n5. BINARY PREDICTIONS:\")\n",
    "print(f\"   Movie 0 genres: {[genres[i] for i in range(len(genres)) if pred_0_binary[i] == 1]}\")\n",
    "print(f\"   Movie 1 genres: {[genres[i] for i in range(len(genres)) if pred_1_binary[i] == 1]}\")\n",
    "print(f\"   Always predicting same genre? {np.array_equal(pred_0_binary, pred_1_binary)}\")\n",
    "\n",
    "# 6. Overall test predictions\n",
    "y_pred_all = model.predict(X_test, verbose=0)\n",
    "y_pred_binary_all = (y_pred_all > 0.5).astype(int)\n",
    "print(f\"\\n6. OVERALL TEST SET:\")\n",
    "print(f\"   Average predicted genres per movie: {y_pred_binary_all.sum(axis=1).mean():.2f}\")\n",
    "print(f\"   Average true genres per movie: {y_test.sum(axis=1).mean():.2f}\")\n",
    "print(f\"   Most common prediction: {genres[np.argmax(y_pred_all.mean(axis=0))]}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CONCLUSION:\")\n",
    "print(\"  Inputs: DIFFERENT\")\n",
    "print(\"  Embeddings: DIFFERENT\")\n",
    "print(\"  LSTM outputs: IDENTICAL <<< BROKEN HERE\")\n",
    "print(\"  Final predictions: IDENTICAL\")\n",
    "print(\"\\n  The LSTM layer is not processing inputs - outputting constant vector.\")\n",
    "print(\"  Likely cause: Vanishing gradients with 6808 timestep sequences.\")\n",
    "print(\"  Fix: Downsample sequences to 1500-2000 and retrain.\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41897a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred_lstm = (model.predict(X_test, verbose=0) > 0.5).astype(int)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"LSTM - PER-GENRE PERFORMANCE\")\n",
    "print(\"=\" * 80)\n",
    "print(classification_report(y_test, y_pred_lstm, target_names=genres, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3654166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model \n",
    "\n",
    "#model.save('lstm_model.keras')\n",
    "#print(\"Model saved to lstm_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6f67a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model \n",
    "\"\"\" from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the saved model\n",
    "model = load_model('lstm_model.keras')\n",
    "print(\"Model loaded successfully\")\n",
    "\n",
    "# Now you can use it for predictions\n",
    "y_pred = model.predict(X_test) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb96e5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils import genres\n",
    "\n",
    "# Pick random sample\n",
    "random_idx = np.random.randint(0, len(X_test))\n",
    "\n",
    "# Get data\n",
    "random_test = X_test[random_idx:random_idx+1]\n",
    "y_true = y_test[random_idx]\n",
    "\n",
    "\n",
    "\n",
    "y_pred = model.predict(random_test)[0]\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "print(f\"True {y_true}\")\n",
    "print(f\"Pred {y_pred_binary}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
