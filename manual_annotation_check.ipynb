{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6142ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3940200 rows from partial_results_3940200.csv\n"
     ]
    }
   ],
   "source": [
    "from utils import load_csv \n",
    "\n",
    "# Usage\n",
    "df = load_csv('partial_results_3940200.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f727212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 55 annotations to 'manual_annotations.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "df_sample = df.sample(n=55, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Available emotions with numbers\n",
    "emotions = ['anger', 'disgust', 'fear', 'joy', 'sadness', 'surprise', 'neutral']\n",
    "emotion_map = {str(i): emotions[i] for i in range(len(emotions))}\n",
    "\n",
    "# Create list to store annotations\n",
    "annotations = []\n",
    "\n",
    "for idx, row in df_sample.iterrows():\n",
    "    clear_output(wait=True)  # Clear previous output\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"MANUAL EMOTION ANNOTATION\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"\\nAvailable emotions:\")\n",
    "    for i, emotion in enumerate(emotions):\n",
    "        print(f\"  {i}: {emotion}\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    print(f\"\\n[{idx+1}/55]\")\n",
    "    print(f\"Sentence: {row['sentence_text']}\")\n",
    "    print(f\"Movie: {row['movie']}, Scene: {row['scene_id']}\")\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"Your annotation: \").strip().lower()\n",
    "        \n",
    "        if user_input == 'quit':\n",
    "            print(f\"\\nStopping. Annotated {len(annotations)} sentences so far.\")\n",
    "            break\n",
    "        elif user_input == 'skip':\n",
    "            break\n",
    "        elif user_input in emotion_map:\n",
    "            user_emotion = emotion_map[user_input]\n",
    "            annotations.append({\n",
    "                'sentence_text': row['sentence_text'],\n",
    "                'movie': row['movie'],\n",
    "                'scene_id': row['scene_id'],\n",
    "                'manual_annotation': user_emotion,\n",
    "                'bert_annotation': row.get('emotion', None)\n",
    "            })\n",
    "            break\n",
    "        else:\n",
    "            print(f\"Invalid input. Type a number 0-6, 'skip', or 'quit'\")\n",
    "    \n",
    "    if user_input == 'quit':\n",
    "        break\n",
    "\n",
    "# Save to CSV\n",
    "clear_output(wait=True)\n",
    "if annotations:\n",
    "    df_annotations = pd.DataFrame(annotations)\n",
    "    df_annotations.to_csv('manual_annotations.csv', index=False)\n",
    "    print(f\"Saved {len(annotations)} annotations to 'manual_annotations.csv'\")\n",
    "else:\n",
    "    print(\"No annotations saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c5281b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 55 manual annotations\n",
      "\n",
      "First few rows:\n",
      "                    sentence_text                          movie  scene_id  \\\n",
      "0              all over the plate       28 Days_0191754_anno.txt    190320   \n",
      "1        She corrects one of them        Dangal_5074352_anno.txt    107707   \n",
      "2                 Congratulations  The Big Blue_0095250_anno.txt    254245   \n",
      "3                    Listen to me        Avatar_0499549_anno.txt    317182   \n",
      "4  That water isn't going to stop      The Cell_0209958_anno.txt    367770   \n",
      "\n",
      "  manual_annotation bert_annotation  \n",
      "0           neutral         neutral  \n",
      "1           neutral         neutral  \n",
      "2               joy         neutral  \n",
      "3             anger         neutral  \n",
      "4              fear         neutral  \n",
      "\n",
      "55 sentences have both manual and BERT annotations\n",
      "\n",
      "================================================================================\n",
      "COMPARISON: MANUAL vs BERT ANNOTATIONS\n",
      "================================================================================\n",
      "\n",
      "Agreement: 18/55 (32.7%)\n",
      "Disagreement: 37/55 (67.3%)\n",
      "\n",
      "Confusion Matrix:\n",
      "(Rows = Manual, Columns = BERT)\n",
      "\n",
      "               ang  dis  fea  joy  sad  sur  neu\n",
      "       anger:    3    0    0    0    0    0    5\n",
      "     disgust:    1    1    0    0    0    1    0\n",
      "        fear:    0    0    1    0    0    0    3\n",
      "         joy:    1    0    0    0    0    0    4\n",
      "     sadness:    0    0    0    0    0    1    1\n",
      "    surprise:    1    1    1    1    1    1    9\n",
      "     neutral:    3    1    1    0    1    0   12\n",
      "\n",
      "================================================================================\n",
      "DETAILED METRICS\n",
      "================================================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.33      0.38      0.35         8\n",
      "     disgust       0.33      0.33      0.33         3\n",
      "        fear       0.33      0.25      0.29         4\n",
      "         joy       0.00      0.00      0.00         5\n",
      "     sadness       0.00      0.00      0.00         2\n",
      "    surprise       0.33      0.07      0.11        15\n",
      "     neutral       0.35      0.67      0.46        18\n",
      "\n",
      "    accuracy                           0.33        55\n",
      "   macro avg       0.24      0.24      0.22        55\n",
      "weighted avg       0.30      0.33      0.27        55\n",
      "\n",
      "\n",
      "================================================================================\n",
      "DISAGREEMENTS (Manual vs BERT)\n",
      "================================================================================\n",
      "\n",
      "Sentence: Congratulations\n",
      "Manual: joy | BERT: neutral\n",
      "Movie: The Big Blue_0095250_anno.txt\n",
      "\n",
      "Sentence: Listen to me\n",
      "Manual: anger | BERT: neutral\n",
      "Movie: Avatar_0499549_anno.txt\n",
      "\n",
      "Sentence: That water isn't going to stop\n",
      "Manual: fear | BERT: neutral\n",
      "Movie: The Cell_0209958_anno.txt\n",
      "\n",
      "Sentence: Don't you constantly question your value - like why was I so easy to cast aside\n",
      "Manual: sadness | BERT: neutral\n",
      "Movie: Dogma_0120655_anno.txt\n",
      "\n",
      "Sentence: Schuyler sighs, wondering what the hell he's doing here\n",
      "Manual: sadness | BERT: surprise\n",
      "Movie: The Game_0119174_anno.txt\n",
      "\n",
      "Sentence: She is wearing a bathrobe and eating a chocolate eclair\n",
      "Manual: neutral | BERT: disgust\n",
      "Movie: Terms of Endearment_0086425_anno.txt\n",
      "\n",
      "Sentence: I need to speak to the colonel\n",
      "Manual: neutral | BERT: fear\n",
      "Movie: Indiana Jones and the Kingdom of the Crystal Skull_0367882_anno.txt\n",
      "\n",
      "Sentence: What does that mean\n",
      "Manual: anger | BERT: neutral\n",
      "Movie: The Best Exotic Marigold Hotel Behind the Story Lights Colours and Smiles_5173200_anno.txt\n",
      "\n",
      "Sentence: Machine SCREAMS, releases Welles and falls back, reaching around to the fork\n",
      "Manual: surprise | BERT: neutral\n",
      "Movie: 8MM_0134273_anno.txt\n",
      "\n",
      "Sentence: (ruefully) I used up my shark dart\n",
      "Manual: anger | BERT: neutral\n",
      "Movie: DeepStar Six_0097179_anno.txt\n",
      "\n",
      "Sentence: She looks at the napkin, it has streaks of red\n",
      "Manual: joy | BERT: neutral\n",
      "Movie: Frances Ha_2347569_anno.txt\n",
      "\n",
      "Sentence: Chase's hand waves out the window until they are out of the parking lot\n",
      "Manual: joy | BERT: neutral\n",
      "Movie: The Life of David Gale_0289992_anno.txt\n",
      "\n",
      "Sentence: There were always two of us in the act\n",
      "Manual: joy | BERT: neutral\n",
      "Movie: Bad Lieutenant_0103759_anno.txt\n",
      "\n",
      "Sentence: (kisses her neck)\n",
      "Manual: joy | BERT: anger\n",
      "Movie: Mystery Men_0132347_anno.txt\n",
      "\n",
      "Sentence: I’1l get you a meeting with Jeff Megall\n",
      "Manual: surprise | BERT: neutral\n",
      "Movie: Thank You for Smoking_0427944_anno.txt\n",
      "\n",
      "Sentence: Another painter is applying the obligatory green horizon over the white at waist height\n",
      "Manual: surprise | BERT: neutral\n",
      "Movie: Never Look Away_5311542_anno.txt\n",
      "\n",
      "Sentence: Branches and leaves fly by as Andy barrels through the foliage\n",
      "Manual: surprise | BERT: neutral\n",
      "Movie: I Spit on Your Grave_1242432_anno.txt\n",
      "\n",
      "Sentence: Donny pulls slightly erratically into the driveway, swerving to avoid hitting a bicycle carelessly left laying on its side\n",
      "Manual: surprise | BERT: fear\n",
      "Movie: I Smile Back_3640682_anno.txt\n",
      "\n",
      "Sentence: I've never been with a woman besides my ex-wife\n",
      "Manual: surprise | BERT: joy\n",
      "Movie: Crazy Stupid Love_1570728_anno.txt\n",
      "\n",
      "Sentence: Do you even know what I mean when I use the term “occult”\n",
      "Manual: neutral | BERT: anger\n",
      "Movie: The Guard_1540133_anno.txt\n",
      "\n",
      "Sentence: He starts cut of the room\n",
      "Manual: neutral | BERT: anger\n",
      "Movie: Diner_0083833_anno.txt\n",
      "\n",
      "Sentence: Chi Chi makes the decision to stop the car in order to save his boss\n",
      "Manual: neutral | BERT: anger\n",
      "Movie: Above the Law_0094602_anno.txt\n",
      "\n",
      "Sentence: The \"room in use\" sign lights up\n",
      "Manual: surprise | BERT: neutral\n",
      "Movie: The Bourne Ultimatum_0440963_anno.txt\n",
      "\n",
      "Sentence: My name's David, too\n",
      "Manual: surprise | BERT: neutral\n",
      "Movie: Sabrina_0047437_anno.txt\n",
      "\n",
      "Sentence: limbo (CONT'D) How many times do I have to tell you\n",
      "Manual: anger | BERT: neutral\n",
      "Movie: Planet of the Apes_0133152_anno.txt\n",
      "\n",
      "Sentence: The car makes a sharp right at the next block and pulls over\n",
      "Manual: fear | BERT: neutral\n",
      "Movie: The Italian Job_0290675_anno.txt\n",
      "\n",
      "Sentence: He's not invited to sit\n",
      "Manual: neutral | BERT: sadness\n",
      "Movie: Collateral_0369339_anno.txt\n",
      "\n",
      "Sentence: Eeet, eet is just perzonal trifles from my homeland -- Shut up\n",
      "Manual: disgust | BERT: anger\n",
      "Movie: Man on the Moon_0125664_anno.txt\n",
      "\n",
      "Sentence: It is a woman's breathless sighs and gasps we hear, but under that, perhaps a man's voice, perhaps not\n",
      "Manual: fear | BERT: neutral\n",
      "Movie: The Assignment_0118647_anno.txt\n",
      "\n",
      "Sentence: You need to have a talk with him\n",
      "Manual: anger | BERT: neutral\n",
      "Movie: After School Special_0371514_anno.txt\n",
      "\n",
      "Sentence: The only thing that's clear is all the cosmetic surgery he's had makes him look like George Hamilton, circa 1962\n",
      "Manual: surprise | BERT: neutral\n",
      "Movie: House on Haunted Hill_0185371_anno.txt\n",
      "\n",
      "Sentence: The maid leaves pretty swiftly, we haven't seen her face, the whole moment seems rather strange\n",
      "Manual: disgust | BERT: surprise\n",
      "Movie: The Artist_1655442_anno.txt\n",
      "\n",
      "Sentence: A week later, Max will die too\n",
      "Manual: surprise | BERT: sadness\n",
      "Movie: 20th Century Women_4385888_anno.txt\n",
      "\n",
      "Sentence: I've found no evidence in the way of lesions, hemorrhaging, tumors\n",
      "Manual: surprise | BERT: disgust\n",
      "Movie: The Butterfly Effect_0289879_anno.txt\n",
      "\n",
      "Sentence: His best stories have been Babar and Winnie the Pooh up to now, with Batman moving up\n",
      "Manual: surprise | BERT: neutral\n",
      "Movie: Kramer vs Kramer_0079417_anno.txt\n",
      "\n",
      "Sentence: And firstly or lastly, depending on the viewer, that the woman on the floor is dressed in a white bridal gown\n",
      "Manual: surprise | BERT: neutral\n",
      "Movie: Kill Bill Vol 1_0266697_anno.txt\n",
      "\n",
      "Sentence: Don't throw that away\n",
      "Manual: surprise | BERT: anger\n",
      "Movie: Human Nature_0219822_anno.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Load manual annotations\n",
    "df_manual = pd.read_csv('manual_annotations.csv')\n",
    "\n",
    "print(f\"Loaded {len(df_manual)} manual annotations\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(df_manual.head())\n",
    "\n",
    "# Check if BERT annotations are present\n",
    "if df_manual['bert_annotation'].isna().all():\n",
    "    print(\"\\nNo BERT annotations found in the CSV.\")\n",
    "    print(\"You need to add BERT predictions to compare.\")\n",
    "else:\n",
    "    # Remove rows where BERT annotation is missing\n",
    "    df_compare = df_manual.dropna(subset=['bert_annotation'])\n",
    "    \n",
    "    print(f\"\\n{len(df_compare)} sentences have both manual and BERT annotations\")\n",
    "    \n",
    "    # Calculate agreement\n",
    "    agreement = (df_compare['manual_annotation'] == df_compare['bert_annotation']).sum()\n",
    "    accuracy = agreement / len(df_compare)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"COMPARISON: MANUAL vs BERT ANNOTATIONS\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\nAgreement: {agreement}/{len(df_compare)} ({accuracy*100:.1f}%)\")\n",
    "    print(f\"Disagreement: {len(df_compare) - agreement}/{len(df_compare)} ({(1-accuracy)*100:.1f}%)\")\n",
    "    \n",
    "    # Confusion matrix\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(\"(Rows = Manual, Columns = BERT)\")\n",
    "    cm = confusion_matrix(df_compare['manual_annotation'], df_compare['bert_annotation'], labels=emotions)\n",
    "    \n",
    "    # Pretty print confusion matrix\n",
    "    print(\"\\n\" + \" \"*15 + \"  \".join(f\"{e[:3]:>3}\" for e in emotions))\n",
    "    for i, emotion in enumerate(emotions):\n",
    "        print(f\"{emotion:>12}:  \" + \"  \".join(f\"{cm[i,j]:>3}\" for j in range(len(emotions))))\n",
    "    \n",
    "    # Detailed classification report\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"DETAILED METRICS\")\n",
    "    print(\"=\"*80)\n",
    "    print(classification_report(df_compare['manual_annotation'], df_compare['bert_annotation'], \n",
    "                                 labels=emotions, zero_division=0))\n",
    "    \n",
    "    # Show disagreements\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"DISAGREEMENTS (Manual vs BERT)\")\n",
    "    print(\"=\"*80)\n",
    "    disagreements = df_compare[df_compare['manual_annotation'] != df_compare['bert_annotation']]\n",
    "    \n",
    "    for idx, row in disagreements.iterrows():\n",
    "        print(f\"\\nSentence: {row['sentence_text']}\")\n",
    "        print(f\"Manual: {row['manual_annotation']} | BERT: {row['bert_annotation']}\")\n",
    "        print(f\"Movie: {row['movie']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e169fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['all over the plate', 'She corrects one of them', 'Congratulations', 'Listen to me', \"That water isn't going to stop\", \"Don't you constantly question your value - like why was I so easy to cast aside\", \"Schuyler sighs, wondering what the hell he's doing here\", 'She is wearing a bathrobe and eating a chocolate eclair', 'I need to speak to the colonel', 'What does that mean', 'Machine SCREAMS, releases Welles and falls back, reaching around to the fork', 'Keep a fifth of something in your desk', '(ruefully) I used up my shark dart', 'She looks at the napkin, it has streaks of red', 'Nice and simple', \"Chase's hand waves out the window until they are out of the parking lot\", 'There were always two of us in the act', '(kisses her neck)', 'And now we back inside--', 'I’1l get you a meeting with Jeff Megall', 'Another painter is applying the obligatory green horizon over the white at waist height', 'Branches and leaves fly by as Andy barrels through the foliage', 'Scarlett ‘4s too frightened for a moment to even utter a ~ sound, She catches hold', 'Donny pulls slightly erratically into the driveway, swerving to avoid hitting a bicycle carelessly left laying on its side', \"I've never been with a woman besides my ex-wife\", 'Do you even know what I mean when I use the term “occult”', 'He starts cut of the room', 'Kill us both', 'Chi Chi makes the decision to stop the car in order to save his boss', 'The \"room in use\" sign lights up', \"My name's David, too\", \"limbo (CONT'D) How many times do I have to tell you\", '\"Mash\" went off -- (getting angry) Yeah, but when they went off people weren\\'t making fun of them', 'The car makes a sharp right at the next block and pulls over', \"She's good to go\", \"He's not invited to sit\", 'Eeet, eet is just perzonal trifles from my homeland -- Shut up', \"That's not a pretty picture\", 'Everyone files out', \"It is a woman's breathless sighs and gasps we hear, but under that, perhaps a man's voice, perhaps not\", 'We have nothing further to say', '(a take) Program', 'There is a blinding flash as it shatters into a million fragments', 'You need to have a talk with him', \"The only thing that's clear is all the cosmetic surgery he's had makes him look like George Hamilton, circa 1962\", \"The maid leaves pretty swiftly, we haven't seen her face, the whole moment seems rather strange\", 'Oh, come on', 'see, the trick to hiding is understanding your surroundings', 'I got some more info on Pedro', 'Jeffrey watches her go then turns and goes inside his house', 'A week later, Max will die too', \"I've found no evidence in the way of lesions, hemorrhaging, tumors\", 'His best stories have been Babar and Winnie the Pooh up to now, with Batman moving up', 'And firstly or lastly, depending on the viewer, that the woman on the floor is dressed in a white bridal gown', \"Don't throw that away\"]\n"
     ]
    }
   ],
   "source": [
    "# Extract just the sentences into a list\n",
    "sentences = df_manual['sentence_text'].tolist()\n",
    "\n",
    "print(sentences)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cda3451",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'I’1l get you a meeting with Jeff Megall'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Convert Claude's emotion numbers to emotion names\u001b[39;00m\n\u001b[32m      9\u001b[39m emotion_num_to_name = {i: emotions[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(emotions))}\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m df_manual[\u001b[33m'\u001b[39m\u001b[33mclaude_annotation\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mdf_manual\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msentence_text\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43memotion_num_to_name\u001b[49m\u001b[43m[\u001b[49m\u001b[43msentence_emotions\u001b[49m\u001b[43m[\u001b[49m\u001b[43ms\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Calculate agreement\u001b[39;00m\n\u001b[32m     15\u001b[39m agreement = (df_manual[\u001b[33m'\u001b[39m\u001b[33mmanual_annotation\u001b[39m\u001b[33m'\u001b[39m] == df_manual[\u001b[33m'\u001b[39m\u001b[33mclaude_annotation\u001b[39m\u001b[33m'\u001b[39m]).sum()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/nlp/lib/python3.11/site-packages/pandas/core/series.py:4719\u001b[39m, in \u001b[36mSeries.map\u001b[39m\u001b[34m(self, arg, na_action)\u001b[39m\n\u001b[32m   4639\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmap\u001b[39m(\n\u001b[32m   4640\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   4641\u001b[39m     arg: Callable | Mapping | Series,\n\u001b[32m   4642\u001b[39m     na_action: Literal[\u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   4643\u001b[39m ) -> Series:\n\u001b[32m   4644\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   4645\u001b[39m \u001b[33;03m    Map values of Series according to an input mapping or function.\u001b[39;00m\n\u001b[32m   4646\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   4717\u001b[39m \u001b[33;03m    dtype: object\u001b[39;00m\n\u001b[32m   4718\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4719\u001b[39m     new_values = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4720\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._constructor(new_values, index=\u001b[38;5;28mself\u001b[39m.index, copy=\u001b[38;5;28;01mFalse\u001b[39;00m).__finalize__(\n\u001b[32m   4721\u001b[39m         \u001b[38;5;28mself\u001b[39m, method=\u001b[33m\"\u001b[39m\u001b[33mmap\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4722\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/nlp/lib/python3.11/site-packages/pandas/core/base.py:925\u001b[39m, in \u001b[36mIndexOpsMixin._map_values\u001b[39m\u001b[34m(self, mapper, na_action, convert)\u001b[39m\n\u001b[32m    922\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[32m    923\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m arr.map(mapper, na_action=na_action)\n\u001b[32m--> \u001b[39m\u001b[32m925\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/nlp/lib/python3.11/site-packages/pandas/core/algorithms.py:1743\u001b[39m, in \u001b[36mmap_array\u001b[39m\u001b[34m(arr, mapper, na_action, convert)\u001b[39m\n\u001b[32m   1741\u001b[39m values = arr.astype(\u001b[38;5;28mobject\u001b[39m, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1742\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1743\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1745\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m lib.map_infer_mask(\n\u001b[32m   1746\u001b[39m         values, mapper, mask=isna(values).view(np.uint8), convert=convert\n\u001b[32m   1747\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/lib.pyx:2999\u001b[39m, in \u001b[36mpandas._libs.lib.map_infer\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36m<lambda>\u001b[39m\u001b[34m(s)\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Convert Claude's emotion numbers to emotion names\u001b[39;00m\n\u001b[32m      9\u001b[39m emotion_num_to_name = {i: emotions[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(emotions))}\n\u001b[32m     10\u001b[39m df_manual[\u001b[33m'\u001b[39m\u001b[33mclaude_annotation\u001b[39m\u001b[33m'\u001b[39m] = df_manual[\u001b[33m'\u001b[39m\u001b[33msentence_text\u001b[39m\u001b[33m'\u001b[39m].map(\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     \u001b[38;5;28;01mlambda\u001b[39;00m s: emotion_num_to_name[\u001b[43msentence_emotions\u001b[49m\u001b[43m[\u001b[49m\u001b[43ms\u001b[49m\u001b[43m]\u001b[49m]\n\u001b[32m     12\u001b[39m )\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Calculate agreement\u001b[39;00m\n\u001b[32m     15\u001b[39m agreement = (df_manual[\u001b[33m'\u001b[39m\u001b[33mmanual_annotation\u001b[39m\u001b[33m'\u001b[39m] == df_manual[\u001b[33m'\u001b[39m\u001b[33mclaude_annotation\u001b[39m\u001b[33m'\u001b[39m]).sum()\n",
      "\u001b[31mKeyError\u001b[39m: 'I’1l get you a meeting with Jeff Megall'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "\n",
    "sentence_emotions = {\n",
    "    'all over the plate': 6,  # neutral\n",
    "    'She corrects one of them': 6,  # neutral\n",
    "    'Congratulations': 3,  # joy\n",
    "    'Listen to me': 0,  # anger\n",
    "    \"That water isn't going to stop\": 2,  # fear\n",
    "    \"Don't you constantly question your value - like why was I so easy to cast aside\": 4,  # sadness\n",
    "    \"Schuyler sighs, wondering what the hell he's doing here\": 4,  # sadness\n",
    "    'She is wearing a bathrobe and eating a chocolate eclair': 6,  # neutral\n",
    "    'I need to speak to the colonel': 6,  # neutral\n",
    "    'What does that mean': 5,  # surprise\n",
    "    'Machine SCREAMS, releases Welles and falls back, reaching around to the fork': 2,  # fear\n",
    "    'Keep a fifth of something in your desk': 6,  # neutral\n",
    "    '(ruefully) I used up my shark dart': 4,  # sadness\n",
    "    'She looks at the napkin, it has streaks of red': 5,  # surprise\n",
    "    'Nice and simple': 3,  # joy\n",
    "    \"Chase's hand waves out the window until they are out of the parking lot\": 6,  # neutral\n",
    "    'There were always two of us in the act': 4,  # sadness\n",
    "    '(kisses her neck)': 3,  # joy\n",
    "    'And now we back inside--': 6,  # neutral\n",
    "    \"I'1l get you a meeting with Jeff Megall\": 6,  # neutral\n",
    "    'Another painter is applying the obligatory green horizon over the white at waist height': 6,  # neutral\n",
    "    'Branches and leaves fly by as Andy barrels through the foliage': 2,  # fear\n",
    "    \"Scarlett '4s too frightened for a moment to even utter a ~ sound, She catches hold\": 2,  # fear\n",
    "    'Donny pulls slightly erratically into the driveway, swerving to avoid hitting a bicycle carelessly left laying on its side': 2,  # fear\n",
    "    \"I've never been with a woman besides my ex-wife\": 4,  # sadness\n",
    "    'Do you even know what I mean when I use the term \"occult\"': 0,  # anger\n",
    "    'He starts cut of the room': 6,  # neutral\n",
    "    'Kill us both': 0,  # anger\n",
    "    'Chi Chi makes the decision to stop the car in order to save his boss': 2,  # fear\n",
    "    'The \"room in use\" sign lights up': 6,  # neutral\n",
    "    \"My name's David, too\": 5,  # surprise\n",
    "    \"limbo (CONT'D) How many times do I have to tell you\": 0,  # anger\n",
    "    '\"Mash\" went off -- (getting angry) Yeah, but when they went off people weren\\'t making fun of them': 0,  # anger\n",
    "    'The car makes a sharp right at the next block and pulls over': 6,  # neutral\n",
    "    \"She's good to go\": 3,  # joy\n",
    "    \"He's not invited to sit\": 1,  # disgust\n",
    "    'Eeet, eet is just perzonal trifles from my homeland -- Shut up': 0,  # anger\n",
    "    \"That's not a pretty picture\": 1,  # disgust\n",
    "    'Everyone files out': 6,  # neutral\n",
    "    \"It is a woman's breathless sighs and gasps we hear, but under that, perhaps a man's voice, perhaps not\": 5,  # surprise\n",
    "    'We have nothing further to say': 0,  # anger\n",
    "    '(a take) Program': 6,  # neutral\n",
    "    'There is a blinding flash as it shatters into a million fragments': 5,  # surprise\n",
    "    'You need to have a talk with him': 6,  # neutral\n",
    "    \"The only thing that's clear is all the cosmetic surgery he's had makes him look like George Hamilton, circa 1962\": 1,  # disgust\n",
    "    \"The maid leaves pretty swiftly, we haven't seen her face, the whole moment seems rather strange\": 5,  # surprise\n",
    "    'Oh, come on': 0,  # anger\n",
    "    'see, the trick to hiding is understanding your surroundings': 6,  # neutral\n",
    "    'I got some more info on Pedro': 6,  # neutral\n",
    "    'Jeffrey watches her go then turns and goes inside his house': 6,  # neutral\n",
    "    'A week later, Max will die too': 4,  # sadness\n",
    "    \"I've found no evidence in the way of lesions, hemorrhaging, tumors\": 6,  # neutral\n",
    "    'His best stories have been Babar and Winnie the Pooh up to now, with Batman moving up': 3,  # joy\n",
    "    'And firstly or lastly, depending on the viewer, that the woman on the floor is dressed in a white bridal gown': 5,  # surprise\n",
    "    \"Don't throw that away\": 0,  # anger\n",
    "}\n",
    "\n",
    "# Load manual annotations\n",
    "df_manual = pd.read_csv('manual_annotations.csv')\n",
    "\n",
    "# Convert Claude's emotion numbers to emotion names\n",
    "emotion_num_to_name = {i: emotions[i] for i in range(len(emotions))}\n",
    "df_manual['claude_annotation'] = df_manual['sentence_text'].map(\n",
    "    lambda s: emotion_num_to_name[sentence_emotions[s]]\n",
    ")\n",
    "\n",
    "# Calculate agreement\n",
    "agreement = (df_manual['manual_annotation'] == df_manual['claude_annotation']).sum()\n",
    "accuracy = agreement / len(df_manual)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"COMPARISON: MANUAL vs CLAUDE ANNOTATIONS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nAgreement: {agreement}/{len(df_manual)} ({accuracy*100:.1f}%)\")\n",
    "print(f\"Disagreement: {len(df_manual) - agreement}/{len(df_manual)} ({(1-accuracy)*100:.1f}%)\")\n",
    "\n",
    "# Confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(\"(Rows = Manual, Columns = Claude)\")\n",
    "cm = confusion_matrix(df_manual['manual_annotation'], df_manual['claude_annotation'], labels=emotions)\n",
    "\n",
    "print(\"\\n\" + \" \"*15 + \"  \".join(f\"{e[:3]:>3}\" for e in emotions))\n",
    "for i, emotion in enumerate(emotions):\n",
    "    print(f\"{emotion:>12}:  \" + \"  \".join(f\"{cm[i,j]:>3}\" for j in range(len(emotions))))\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DETAILED METRICS\")\n",
    "print(\"=\"*80)\n",
    "print(classification_report(df_manual['manual_annotation'], df_manual['claude_annotation'], \n",
    "                             labels=emotions, zero_division=0))\n",
    "\n",
    "# Show disagreements\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DISAGREEMENTS (Manual vs Claude)\")\n",
    "print(\"=\"*80)\n",
    "disagreements = df_manual[df_manual['manual_annotation'] != df_manual['claude_annotation']]\n",
    "\n",
    "for idx, row in disagreements.iterrows():\n",
    "    print(f\"\\nSentence: {row['sentence_text']}\")\n",
    "    print(f\"Manual: {row['manual_annotation']} | Claude: {row['claude_annotation']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
